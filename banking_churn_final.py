# -*- coding: utf-8 -*-
"""refined_banking_churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mlO6u-aMpWIrR-vGeP5F2z_lSODbzZcc
"""

## BANKING CUSTOMER CHURN EDA

# Setup and Data Loading
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Set style once
plt.style.use('default')
sns.set_palette("Set2")

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')
# Load data
df = pd.read_csv("/content/drive/MyDrive/joined_bank2.csv")

# Data preprocessing
df['Balance'] = df['Balance'].astype(float)

# Create age and balance groups
df['AgeGroup'] = pd.cut(df['Age'], bins=[18,30,40,50,60,100],
                       labels=['18-30','31-40','41-50','51-60','60+'])

df['BalanceGroup'] = pd.qcut(df.loc[df['Balance']>0, 'Balance'], 4,
                            labels=['Q1 (Low)','Q2','Q3','Q4 (High)'])
df['BalanceGroup'] = df['BalanceGroup'].astype(str)
df.loc[df['Balance']==0, 'BalanceGroup'] = 'Zero Balance'

# === VISUALIZATIONS ===
def save_plot(filename, dpi=300):
    # Helper function to save plots consistently
    plt.tight_layout()
    plt.savefig(filename, dpi=dpi, bbox_inches='tight')
    plt.close()

# 3. Churn rates by segments
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Age groups
age_churn = df.groupby('AgeGroup')['Exited'].mean()
age_churn.plot(kind='bar', ax=axes[0,0], color='skyblue')
axes[0,0].set_title('Churn Rate by Age Group')
axes[0,0].tick_params(axis='x', rotation=45)

# Balance groups
balance_churn = df.groupby('BalanceGroup')['Exited'].mean()
balance_churn.plot(kind='bar', ax=axes[0,1], color='lightcoral')
axes[0,1].set_title('Churn Rate by Balance Group')
axes[0,1].tick_params(axis='x', rotation=45)

# Geography
geo_churn = df.groupby('Geography')['Exited'].mean()
geo_churn.plot(kind='bar', ax=axes[1,0], color='lightgreen')
axes[1,0].set_title('Churn Rate by Country')

# Gender
gender_churn = df.groupby('Gender')['Exited'].mean()
gender_churn.plot(kind='bar', ax=axes[1,1], color='gold')
axes[1,1].set_title('Churn Rate by Gender')

save_plot("churn_rates_by_segments.png")

# Basic data exploration
print("=== DATA OVERVIEW ===")
print(df.head())
print(f"\nDataset shape: {df.shape}")
print(f"\nChurn rate: {df['Exited'].mean():.2%}")
print("\n" + "="*50)

# === SUMMARY STATISTICS ===
print("\n=== CHURN ANALYSIS SUMMARY ===")

# Numerical features by churn status
print("\nNumerical Features by Churn Status:")
num_cols = ["CreditScore", "Age", "Balance", "EstimatedSalary", "Tenure", "NumOfProducts"]
num_summary = df.groupby("Exited")[num_cols].agg(["mean", "median", "std"])
print(num_summary.round(2))

# Categorical features churn rates
print("\nChurn Rates by Category:")
categorical_cols = ['Gender', 'Geography', 'IsActiveMember', 'HasCrCard']
for col in categorical_cols:
    churn_rate = df.groupby(col)['Exited'].mean()
    print(f"\n{col}:")
    for category, rate in churn_rate.items():
        print(f"  {category}: {rate:.2%}")

# Key insights
print("\n=== KEY INSIGHTS ===")
print(f"• Highest churn age group: {age_churn.idxmax()} ({age_churn.max():.2%})")
print(f"• Highest churn country: {geo_churn.idxmax()} ({geo_churn.max():.2%})")
print(f"• Highest churn balance group: {balance_churn.idxmax()} ({balance_churn.max():.2%})")
print(f"• Active vs Inactive churn: {df.groupby('IsActiveMember')['Exited'].mean().to_dict()}")

## Analyzing distribution pattern

fig, axes = plt.subplots(2, 2, figsize=(10, 7))
num_col = ['Age','CreditScore','Balance','EstimatedSalary']
axes=axes.flatten()

for i,col in enumerate(num_col):
    sns.histplot(df[col], bins="fd", kde=True, ax=axes[i])
    axes[i].set_title(f"{col} Distribution")

    skewness = df[col].skew()
    kurtosis = df[col].kurt()

    axes[i].text(0.95, 0.95,f"skewness={skewness:.2f} \ kurtosis={kurtosis:.2f}",
                 transform=axes[i].transAxes,
                 fontsize=9, va='top', ha='right',
                 bbox=dict(facecolor='white', alpha=0.7, edgecolor='gray'))


plt.tight_layout()
plt.show()
save_plot("Distribution graphs.png")

# Churn by demographics (combined subplot)
fig, axes = plt.subplots(1, 4, figsize=(10, 7))

# Gender vs Churn
sns.countplot(x='Gender', hue='Exited', data=df, ax=axes[0])
axes[0].set_title("Churn by Gender")

# Geography vs Churn
sns.countplot(x='Geography', hue='Exited', data=df, ax=axes[1])
axes[1].set_title("Churn by Country")

# Active Member vs Churn
sns.countplot(x='IsActiveMember', hue='Exited', data=df, ax=axes[2])
axes[2].set_title("Churn by Active Status")

# Product Holding vs Churn
sns.countplot(x='NumOfProducts', hue='Exited', data=df, ax=axes[3])
axes[3].set_title("Churn by Product Holding")

save_plot("demographic_churn_analysis.png")

## Bivariate analysis

fig, axes = plt.subplots(2, 2, figsize=(10, 7))
num_var = ['Age','CreditScore','Balance','EstimatedSalary']
axes=axes.flatten()

for i,var in enumerate(num_var):
    sns.boxplot(data=df, x='Exited', y=var, ax=axes[i])
    axes[i].set_title(f"Churn rates by {var}")

plt.tight_layout()
save_plot("Boxplots.png")

# Heatmaps
corr = df[num_var + ['Exited']].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', center=0)
save_plot("Heatmap.png")

## Feature engineering

df['age_group'] = pd.cut(df['Age'], bins=[0, 30, 40, 50, 60, 100],
                        labels=['young', 'early_career', 'mid_career', 'senior', 'elderly'])

df['has_balance'] = (df['Balance'] > 0).astype(int)
df['high_balance'] = (df['Balance'] > df['Balance'].quantile(0.75)).astype(int)

df['age_balance_interaction'] = df['Age'] * df['Balance'] / 1000000

df['tenure_group'] = pd.cut(df['Tenure'], bins=[0,2,4,6,8,10], labels=['new','lower-middle','middle','upper-middle','long'])

df['balance_salary_ratio'] = df['Balance'] / (df['EstimatedSalary']+1)

## Statistical tests

# Categorical variables (Chi-square)
from scipy.stats import chi2_contingency
import pandas as pd

def chi_square_test(feature, target='Exited'):
    contingency = pd.crosstab(df[feature], df[target])
    chi2, p, dof, expected = chi2_contingency(contingency)
    return {'feature': feature, 'chi2': chi2, 'p_value': p}

for f in ['age_group', 'has_balance', 'tenure_group']:
    if f in df.columns:
        print(chi_square_test(f))

# Numerical variables (T-test)
from scipy.stats import ttest_ind

def t_test_numeric(feature, target='Exited'):
    churned = df[df[target] == 1][feature]
    stayed = df[df[target] == 0][feature]
    t_stat, p = ttest_ind(churned, stayed, equal_var=False)
    return {'feature': feature, 't_stat': t_stat, 'p_value': p}

for f in ['Age', 'Balance', 'age_balance_interaction']:
    if f in df.columns:
        print(t_test_numeric(f))

## Random forest
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

X = df.drop(columns=['Exited'])
y = df['Exited']

# Train-test split (70/30 is common)
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.3,
                                                    random_state=42,
                                                    stratify=y)

# One-hot encoding
X_train = pd.get_dummies(X_train, drop_first=True)
X_test = pd.get_dummies(X_test, drop_first=True)
X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)

# Training default model
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

# Evaluation
y_pred = rf.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

# Feature importance
import matplotlib.pyplot as plt

importances = pd.Series(rf.feature_importances_, index=X_train.columns)
importances.sort_values(ascending=False).head(15).plot(kind='barh')
save_plot("randomforest.png")
plt.show()

from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from scipy.stats import randint

# Define parameter grid for random search
param_dist = {
    "n_estimators": randint(100, 500),
    "max_depth": randint(3, 20),
    "min_samples_split": randint(2, 20),
    "min_samples_leaf": randint(1, 10),
    "max_features": ["sqrt", "log2", None]
}
# Initialize the model
rf = RandomForestClassifier(random_state=42, class_weight="balanced")

# RandomizedSearchCV
random_search = RandomizedSearchCV(
    rf,
    param_distributions=param_dist,
    n_iter=20,                # quick run (try ~20 random combos)
    scoring="f1_macro",       # optimize for balanced class performance
    cv=3,
    verbose=1,
    n_jobs=-1,
    random_state=42
)

# Fit on training data
random_search.fit(X_train, y_train)

print("Best parameters:", random_search.best_params_)
print("Best CV score:", random_search.best_score_)

# Test performance
best_rf = random_search.best_estimator_
y_pred_best = best_rf.predict(X_test)

print("Test Accuracy:", accuracy_score(y_test, y_pred_best))
print(classification_report(y_test, y_pred_best))

